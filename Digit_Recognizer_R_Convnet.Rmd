---
title: "Kaggle_Digit_Recognizer"
author: "Christopher Chen"
date: "2024-09-15"
output: html_document
---

```{r  }
library (tidyverse)
```

```{r }
df.train=read.csv('C:/Users/chris/Documents/Projects/GitHub R/Kaggle/Kaggle---Digit-Recognizer/Dataset/train.csv')
df.test=data.matrix (read.csv('C:/Users/chris/Documents/Projects/GitHub R/Kaggle/Kaggle---Digit-Recognizer/Dataset/test.csv'))
```

```{r }
library(keras)

mnist <- dataset_mnist()
c(c(train_images, train_labels), c(test_images, test_labels)) %<-% mnist

```

#Visualize the digits using raster fucntion
```{r }
digit <- train_images[45,,]
plot(as.raster(digit, max = 255))
```

#Callback Functions
```{r }
#Early stopping
cb_stop <- callback_early_stopping(monitor = 'val_loss', patience = 8)

#CSV Logging
version <- format(Sys.time(), "%Y%m%d%H%M")
cb_csv_log <- callback_csv_logger(paste0("C:/Users/chris/Documents/Projects/GitHub R/Kaggle/Kaggle---Digit-Recogn/Log_Dir/log_", version ,".csv"), separator= ",", append = FALSE)

#Learning rate Scheduler
schedule <- function(epoch, lr) {
  if (epoch >= 4) {
    new_lr <- lr * .98
  } else {
    new_lr <- lr * 1
  }
   return(new_lr)
}
cb_scheduler <- callback_learning_rate_scheduler(schedule)


#Tensorboard 
#dir.create("Log_Dir")
log_dir <- "C:/Users/chris/Documents/Projects/GitHub R/Kaggle/Kaggle---Digit-Recogn/Log_Dir"
log_files <- list.files(path=paste0(log_dir,"/train/"), pattern ="\\.v2$", full.names = TRUE)
unlink(log_files)
log_files <- list.files(path=paste0(log_dir,"/validation/"), pattern ="\\.v2$", full.names = TRUE)
unlink(log_files)
cb_tensorboard <-
  callback_tensorboard(
      log_dir = log_dir,
      histogram_freq = 1,
      embeddings_freq =  1,
      write_grads = TRUE,
      write_images = TRUE)
tensorboard(log_dir, launch_browser = TRUE)

#Lambda
on_epoch_begin <- function(epoch, logs) {
  print(paste("Beginning epoch", epoch+1))
}

on_epoch_end <- function(epoch, logs) {
  print(paste("Ending epoch", epoch+1, "with logs:"))
  print(logs)
}

# Create the lambda callback
cb_lambda <- callback_lambda(
  on_epoch_begin = on_epoch_begin,
  on_epoch_end = on_epoch_end
)

#Reduce learning rate on plateau
cb_reduce_lr_plateau <- callback_reduce_lr_on_plateau(
  monitor = "val_loss",
  factor = 0.1,
  patience = 10
)

#Custom callback
LossHistory <- R6::R6Class("LossHistory",
  inherit = KerasCallback,
  
  public = list(
    
    losses = NULL,
     
    on_batch_end = function(batch, logs = list()) {
      self$losses <- c(self$losses, logs[["loss"]])
    }
))
cb_history <- LossHistory$new()

callbacks_list <- list(cb_stop, cb_csv_log, cb_tensorboard, cb_reduce_lr_plateau, cb_scheduler, cb_history)
cb_history$losses
```

```{r, eval=FALSE }
# Reshape datasets in Keras
train_images <- array_reshape(train_images, c(60000, 28 * 28))
train_images <- train_images / 255

test_images <- array_reshape(test_images, c(10000, 28 * 28))
test_images <- test_images / 255

train_labels <- to_categorical(train_labels)
test_labels <- to_categorical(test_labels)
```

```{r, eval=FALSE }
network <- keras_model_sequential() %>%
  layer_dense(units = 512, activation = "relu", input_shape = c(784)) %>%
  layer_dense(units = 10, activation = "softmax")

Learning_Rate = .0005
opt=optimizer_adamax(learning_rate = Learning_Rate)
network %>% compile(
  optimizer = opt,
  loss = "categorical_crossentropy",
  metrics = c("accuracy")
)

network %>% fit(train_images, train_labels, epochs = 15, batch_size = 128)

metrics <- network %>% evaluate(test_images, test_labels)
metrics

history <- network %>% fit(
  train_images,
  train_labels,
  epochs = 15,
  batch_size = 128,
  validation_data = list(test_images, test_labels)
)
plot (history)
```

```{r }
convnet <- keras_model_sequential() %>%
  layer_conv_2d(filters = 32, kernel_size = c(3, 3), 
                activation = "relu",
                input_shape = c(28, 28, 1),
                kernel_initializer = initializer_lecun_normal(seed = 123)) %>%
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  layer_conv_2d(filters = 64, 
                kernel_size = c(3, 3), 
                activation = "relu",
                kernel_initializer = initializer_lecun_normal(seed = 123)) %>%
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  layer_conv_2d(filters = 64, 
                kernel_size = c(3, 3), 
                activation = "relu",
                kernel_initializer = initializer_lecun_normal(seed = 123)) %>%
  layer_flatten() %>%
  layer_dense(units = 64, 
              activation = "relu") %>%
  layer_dense(units = 10, 
              activation = "softmax")
```

```{r }
Learning_Rate = .01
opt=optimizer_adamax(learning_rate = Learning_Rate)
# Pay attention the tensor is different

train_images <- array_reshape(train_images, c(60000, 28, 28, 1))
train_images <- train_images / 255
test_images <- array_reshape(test_images, c(10000, 28, 28, 1))
test_images <- test_images / 255

train_labels <- to_categorical(train_labels)
test_labels <- to_categorical(test_labels)

convnet %>% compile(
  optimizer = opt,
  loss = "categorical_crossentropy",
  metrics = c("accuracy")
)

```


```{r }
history <- convnet %>% fit(
  train_images,
  train_labels,
  epochs = 20,
  batch_size = 64,
  validation_data = list(test_images, test_labels),
  callbacks = callbacks_list,
)

results <- convnet %>% evaluate(test_images, test_labels)
results

plot(history)
```

#Retrain
```{r }
eps3 = ifelse(cb_stop$stopped_epoch > 0, cb_stop$stopped_epoch, eps)
eps3
```

```{r }
test = df.test/255

dim(test) <-c(nrow(test),784)

convnet_test = array_reshape(test, c(28000, 28, 28,1))

pred=convnet %>% predict(convnet_test) %>% k_argmax()
Label=as.data.frame (as.vector (pred))
```

```{r }
library(openxlsx)
END_DATE <- Sys.Date()
FILE_PATH <- paste0(dirname(rstudioapi::getActiveDocumentContext()$path), "/Output/Submission_convnet_",format(END_DATE,"%Y%m%d"),".csv")
df.test=(read.csv('C:/Users/chris/Documents/Projects/GitHub R/Kaggle/Kaggle---Digit-Recognizer/Dataset/test.csv'))
ImageId=as.data.frame(1:nrow(df.test))
submission<-as.data.frame(cbind(ImageId,Label))
colnames (submission)=c('ImageId','Label')
write.csv(submission, file=FILE_PATH, row.names=F)

```

